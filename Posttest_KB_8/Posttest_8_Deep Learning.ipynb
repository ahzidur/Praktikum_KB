{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Posttest 8 Deep Learning\n",
    "## Ahmad Zidan Maulidinnur\n",
    "## 2009106018\n",
    "## Kecerdasan Buatan A2 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proses Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = load_wine(as_frame=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = wine.data #Feature\n",
    "y = wine.target #Target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "panjang x train : 142\n",
      " panjang y train : 142\n",
      " panjang x test : 36\n",
      " panjang y test : 36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'panjang x train : {len(x_train)}\\n',\n",
    "f'panjang y train : {len(y_train)}\\n',\n",
    "f'panjang x test : {len(x_test)}\\n',\n",
    "f'panjang y test : {len(y_test)}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Standarisasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_scaled_train = ss.fit_transform(x_train)\n",
    "x_scaled_test = ss.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, 3)\n",
    "y_test = to_categorical(y_test, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Membuat Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 25)                350       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 25)                650       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 25)                650       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 3)                 78        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,728\n",
      "Trainable params: 1,728\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "#Input Layer\n",
    "model.add(Dense(25, activation='relu', input_dim=13))\n",
    "\n",
    "#Hidden Layer\n",
    "model.add(Dense(25, activation='relu'))\n",
    "model.add(Dense(25, activation='relu'))\n",
    "\n",
    "\n",
    "#Output Layer\n",
    "model.add(Dense(3, activation='softmax')) \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mengoptimasi model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=Adam(),\n",
    "    loss = categorical_crossentropy,\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the early stopping callback\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Define a callback to monitor val_accuracy\n",
    "monitor_val_acc = EarlyStopping(monitor='accuracy',\n",
    "                                patience=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "5/5 [==============================] - 1s 81ms/step - loss: 37.4954 - accuracy: 0.2676 - val_loss: 24.1505 - val_accuracy: 0.2778\n",
      "Epoch 2/120\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 11.9839 - accuracy: 0.3592 - val_loss: 2.4637 - val_accuracy: 0.1389\n",
      "Epoch 3/120\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 5.8795 - accuracy: 0.2465 - val_loss: 7.6757 - val_accuracy: 0.4444\n",
      "Epoch 4/120\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 6.0860 - accuracy: 0.3028 - val_loss: 2.0495 - val_accuracy: 0.2778\n",
      "Epoch 5/120\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5461 - accuracy: 0.3873 - val_loss: 4.4474 - val_accuracy: 0.2778\n",
      "Epoch 6/120\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.3279 - accuracy: 0.2887 - val_loss: 2.2207 - val_accuracy: 0.4444\n",
      "Epoch 7/120\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2.0626 - accuracy: 0.3944 - val_loss: 2.7204 - val_accuracy: 0.2778\n",
      "Epoch 8/120\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.6332 - accuracy: 0.5141 - val_loss: 1.2987 - val_accuracy: 0.4444\n",
      "Epoch 9/120\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.3201 - accuracy: 0.3099 - val_loss: 1.3234 - val_accuracy: 0.3889\n",
      "Epoch 10/120\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.0801 - accuracy: 0.5282 - val_loss: 1.1768 - val_accuracy: 0.5000\n",
      "Epoch 11/120\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.0201 - accuracy: 0.6408 - val_loss: 0.9168 - val_accuracy: 0.4722\n",
      "Epoch 12/120\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.9030 - accuracy: 0.5282 - val_loss: 0.9597 - val_accuracy: 0.5833\n",
      "Epoch 13/120\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.8694 - accuracy: 0.6056 - val_loss: 1.1344 - val_accuracy: 0.4444\n",
      "Epoch 14/120\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.8886 - accuracy: 0.5634 - val_loss: 0.8731 - val_accuracy: 0.5833\n",
      "Epoch 15/120\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.8412 - accuracy: 0.6056 - val_loss: 0.8405 - val_accuracy: 0.5556\n",
      "Epoch 16/120\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.8523 - accuracy: 0.5282 - val_loss: 0.9414 - val_accuracy: 0.5556\n",
      "Epoch 17/120\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.8096 - accuracy: 0.6127 - val_loss: 0.9024 - val_accuracy: 0.5833\n",
      "Epoch 18/120\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.8090 - accuracy: 0.5915 - val_loss: 0.8885 - val_accuracy: 0.5556\n",
      "Epoch 19/120\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.7441 - accuracy: 0.6831 - val_loss: 0.8314 - val_accuracy: 0.5833\n",
      "Epoch 20/120\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7505 - accuracy: 0.6549 - val_loss: 0.8592 - val_accuracy: 0.5278\n",
      "Epoch 21/120\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.7476 - accuracy: 0.6620 - val_loss: 0.8376 - val_accuracy: 0.5278\n",
      "Epoch 22/120\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.7311 - accuracy: 0.6690 - val_loss: 0.7995 - val_accuracy: 0.6667\n",
      "Epoch 23/120\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.7251 - accuracy: 0.6901 - val_loss: 0.8313 - val_accuracy: 0.5278\n",
      "Epoch 24/120\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.6992 - accuracy: 0.6972 - val_loss: 0.7918 - val_accuracy: 0.5556\n",
      "Epoch 25/120\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6968 - accuracy: 0.6690 - val_loss: 0.8808 - val_accuracy: 0.5556\n",
      "Epoch 26/120\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.7158 - accuracy: 0.6901 - val_loss: 0.8028 - val_accuracy: 0.5556\n",
      "Epoch 27/120\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.6717 - accuracy: 0.7113 - val_loss: 0.8209 - val_accuracy: 0.6389\n",
      "Epoch 28/120\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.6793 - accuracy: 0.7113 - val_loss: 0.7910 - val_accuracy: 0.5278\n",
      "Epoch 29/120\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.6696 - accuracy: 0.6901 - val_loss: 0.7685 - val_accuracy: 0.5556\n",
      "Epoch 30/120\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.6849 - accuracy: 0.6901 - val_loss: 0.8055 - val_accuracy: 0.5556\n",
      "Epoch 31/120\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.6549 - accuracy: 0.7254 - val_loss: 0.7885 - val_accuracy: 0.5278\n",
      "Epoch 32/120\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.6813 - accuracy: 0.6408 - val_loss: 0.8651 - val_accuracy: 0.5556\n",
      "Epoch 33/120\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.7046 - accuracy: 0.7042 - val_loss: 0.7861 - val_accuracy: 0.5556\n",
      "Epoch 34/120\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.6868 - accuracy: 0.6831 - val_loss: 0.8005 - val_accuracy: 0.5833\n",
      "Epoch 35/120\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.6763 - accuracy: 0.6690 - val_loss: 0.8233 - val_accuracy: 0.5556\n",
      "Epoch 36/120\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.6269 - accuracy: 0.7042 - val_loss: 0.7702 - val_accuracy: 0.6667\n",
      "Epoch 37/120\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.6429 - accuracy: 0.7113 - val_loss: 0.7954 - val_accuracy: 0.5278\n",
      "Epoch 38/120\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.6739 - accuracy: 0.6620 - val_loss: 0.7916 - val_accuracy: 0.5556\n",
      "Epoch 39/120\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.7033 - accuracy: 0.6620 - val_loss: 0.8297 - val_accuracy: 0.6111\n",
      "Epoch 40/120\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.7299 - accuracy: 0.6197 - val_loss: 0.8675 - val_accuracy: 0.5833\n",
      "Epoch 41/120\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.6199 - accuracy: 0.7183 - val_loss: 0.7810 - val_accuracy: 0.7500\n",
      "Epoch 42/120\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.6430 - accuracy: 0.7183 - val_loss: 0.8099 - val_accuracy: 0.5556\n",
      "Epoch 43/120\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.6379 - accuracy: 0.6901 - val_loss: 0.7720 - val_accuracy: 0.5278\n",
      "Epoch 44/120\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.6051 - accuracy: 0.7606 - val_loss: 0.7529 - val_accuracy: 0.5833\n",
      "Epoch 45/120\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.6111 - accuracy: 0.7324 - val_loss: 0.7647 - val_accuracy: 0.5278\n",
      "Epoch 46/120\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.5881 - accuracy: 0.7606 - val_loss: 0.7450 - val_accuracy: 0.6111\n",
      "Epoch 47/120\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 0.6050 - accuracy: 0.7183 - val_loss: 0.7955 - val_accuracy: 0.5833\n",
      "Epoch 48/120\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 0.6338 - accuracy: 0.6972 - val_loss: 0.7748 - val_accuracy: 0.6111\n",
      "Epoch 49/120\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.6195 - accuracy: 0.7113 - val_loss: 0.8829 - val_accuracy: 0.5833\n",
      "Epoch 50/120\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.6154 - accuracy: 0.7324 - val_loss: 0.7731 - val_accuracy: 0.5278\n",
      "Epoch 51/120\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.6003 - accuracy: 0.7183 - val_loss: 0.8189 - val_accuracy: 0.5833\n",
      "Epoch 52/120\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.6045 - accuracy: 0.7676 - val_loss: 0.7558 - val_accuracy: 0.5556\n",
      "Epoch 53/120\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.6306 - accuracy: 0.7113 - val_loss: 0.7463 - val_accuracy: 0.5833\n",
      "Epoch 54/120\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.5848 - accuracy: 0.7465 - val_loss: 0.7846 - val_accuracy: 0.5833\n",
      "Epoch 55/120\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.5909 - accuracy: 0.7183 - val_loss: 0.7397 - val_accuracy: 0.5833\n",
      "Epoch 56/120\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.5881 - accuracy: 0.7254 - val_loss: 0.7943 - val_accuracy: 0.5833\n",
      "Epoch 57/120\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.6307 - accuracy: 0.7113 - val_loss: 0.7411 - val_accuracy: 0.6667\n",
      "Epoch 58/120\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.6149 - accuracy: 0.7113 - val_loss: 0.7834 - val_accuracy: 0.5278\n",
      "Epoch 59/120\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.6339 - accuracy: 0.6479 - val_loss: 0.8540 - val_accuracy: 0.5833\n",
      "Epoch 60/120\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.6112 - accuracy: 0.7183 - val_loss: 0.7393 - val_accuracy: 0.5833\n",
      "Epoch 61/120\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.6143 - accuracy: 0.6901 - val_loss: 0.7423 - val_accuracy: 0.6111\n",
      "Epoch 62/120\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.6605 - accuracy: 0.6972 - val_loss: 0.7624 - val_accuracy: 0.5833\n",
      "Epoch 63/120\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.5865 - accuracy: 0.7113 - val_loss: 0.7786 - val_accuracy: 0.5833\n",
      "Epoch 64/120\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.5942 - accuracy: 0.7394 - val_loss: 0.7729 - val_accuracy: 0.6111\n",
      "Epoch 65/120\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.5912 - accuracy: 0.7183 - val_loss: 0.7431 - val_accuracy: 0.6667\n",
      "Epoch 66/120\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.6152 - accuracy: 0.7042 - val_loss: 0.7879 - val_accuracy: 0.5833\n",
      "Epoch 67/120\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.5931 - accuracy: 0.7113 - val_loss: 0.7429 - val_accuracy: 0.6111\n",
      "Epoch 68/120\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.6031 - accuracy: 0.6831 - val_loss: 0.7877 - val_accuracy: 0.5833\n",
      "Epoch 69/120\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.5689 - accuracy: 0.7535 - val_loss: 0.7522 - val_accuracy: 0.6667\n",
      "Epoch 70/120\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.5511 - accuracy: 0.7465 - val_loss: 0.8235 - val_accuracy: 0.5833\n",
      "Epoch 71/120\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.5492 - accuracy: 0.7746 - val_loss: 0.7612 - val_accuracy: 0.5833\n",
      "Epoch 72/120\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.5563 - accuracy: 0.7183 - val_loss: 0.7358 - val_accuracy: 0.5833\n",
      "Epoch 73/120\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.5306 - accuracy: 0.7817 - val_loss: 0.7330 - val_accuracy: 0.6111\n",
      "Epoch 74/120\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.5555 - accuracy: 0.7254 - val_loss: 0.7974 - val_accuracy: 0.5833\n",
      "Epoch 75/120\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.6037 - accuracy: 0.7324 - val_loss: 0.8355 - val_accuracy: 0.7222\n",
      "Epoch 76/120\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.6069 - accuracy: 0.7183 - val_loss: 0.9292 - val_accuracy: 0.6111\n",
      "Epoch 77/120\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.5697 - accuracy: 0.7042 - val_loss: 0.8002 - val_accuracy: 0.5278\n",
      "Epoch 78/120\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.5769 - accuracy: 0.7113 - val_loss: 0.8322 - val_accuracy: 0.6111\n",
      "Epoch 79/120\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.5511 - accuracy: 0.7676 - val_loss: 0.7262 - val_accuracy: 0.6944\n",
      "Epoch 80/120\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.5293 - accuracy: 0.7606 - val_loss: 0.7592 - val_accuracy: 0.6389\n",
      "Epoch 81/120\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.5038 - accuracy: 0.7887 - val_loss: 0.7329 - val_accuracy: 0.6111\n",
      "Epoch 82/120\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.5666 - accuracy: 0.7042 - val_loss: 0.7234 - val_accuracy: 0.7222\n",
      "Epoch 83/120\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.5174 - accuracy: 0.7746 - val_loss: 0.7924 - val_accuracy: 0.5833\n",
      "Epoch 84/120\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.5033 - accuracy: 0.8099 - val_loss: 0.7156 - val_accuracy: 0.6667\n",
      "Epoch 85/120\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.4936 - accuracy: 0.7958 - val_loss: 0.7216 - val_accuracy: 0.6111\n",
      "Epoch 86/120\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.5048 - accuracy: 0.7676 - val_loss: 0.7718 - val_accuracy: 0.6667\n",
      "Epoch 87/120\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.5050 - accuracy: 0.7817 - val_loss: 0.7263 - val_accuracy: 0.6389\n",
      "Epoch 88/120\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.4893 - accuracy: 0.7958 - val_loss: 0.7857 - val_accuracy: 0.6667\n",
      "Epoch 89/120\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.5010 - accuracy: 0.7887 - val_loss: 0.7409 - val_accuracy: 0.5833\n",
      "Epoch 90/120\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.5082 - accuracy: 0.7887 - val_loss: 0.7233 - val_accuracy: 0.7500\n",
      "Epoch 91/120\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.5117 - accuracy: 0.7817 - val_loss: 0.7149 - val_accuracy: 0.6667\n",
      "Epoch 92/120\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.4818 - accuracy: 0.8028 - val_loss: 0.7046 - val_accuracy: 0.6667\n",
      "Epoch 93/120\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.5207 - accuracy: 0.7676 - val_loss: 0.7425 - val_accuracy: 0.6944\n",
      "Epoch 94/120\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.4979 - accuracy: 0.8028 - val_loss: 0.7390 - val_accuracy: 0.6111\n",
      "Epoch 95/120\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4933 - accuracy: 0.7676 - val_loss: 0.7565 - val_accuracy: 0.6944\n",
      "Epoch 96/120\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.5249 - accuracy: 0.7887 - val_loss: 0.7398 - val_accuracy: 0.5556\n",
      "Epoch 97/120\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4925 - accuracy: 0.7465 - val_loss: 0.7813 - val_accuracy: 0.6944\n",
      "Epoch 98/120\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4960 - accuracy: 0.7958 - val_loss: 0.7447 - val_accuracy: 0.6111\n",
      "Epoch 99/120\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.5212 - accuracy: 0.7606 - val_loss: 0.6973 - val_accuracy: 0.7222\n",
      "Epoch 100/120\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.5159 - accuracy: 0.8028 - val_loss: 0.7523 - val_accuracy: 0.6111\n",
      "Epoch 101/120\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.5412 - accuracy: 0.7535 - val_loss: 0.7778 - val_accuracy: 0.6111\n",
      "Epoch 102/120\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6005 - accuracy: 0.7394 - val_loss: 0.7794 - val_accuracy: 0.6111\n",
      "Epoch 103/120\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.5336 - accuracy: 0.7394 - val_loss: 0.8565 - val_accuracy: 0.6389\n",
      "Epoch 104/120\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.5905 - accuracy: 0.7394 - val_loss: 0.7191 - val_accuracy: 0.6667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19d6537e2b0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    x = x_train, \n",
    "    y = y_train,\n",
    "    validation_data=(x_test,y_test),\n",
    "    epochs=120,\n",
    "    verbose=1,\n",
    "    callbacks=[monitor_val_acc]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "1d5c1156327dacead463cc502c55ebae8ce9c8c01979cf154173ff808e75bf55"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
